{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "428b7029386d4f44a88674ffa2c79881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1412f8066a224971b738b743952bc195",
              "IPY_MODEL_6256359a6f2442ccb025b27ba501fffa",
              "IPY_MODEL_7c23e6c95df6474a81594615a7d9b2ef"
            ],
            "layout": "IPY_MODEL_46a41677258149558d0df7f4de2bd124"
          }
        },
        "1412f8066a224971b738b743952bc195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38b42a7b0164b3b8f69a93dc65a85d4",
            "placeholder": "​",
            "style": "IPY_MODEL_7da7d206b0084bfbacacee65922d43bc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6256359a6f2442ccb025b27ba501fffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b05caa1d134ba4a7bcf66b86c97e9b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b76ba7f45804e93b02c4caf6ccf4b89",
            "value": 2
          }
        },
        "7c23e6c95df6474a81594615a7d9b2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3a4bc17f35485bb426cdc5bf0049ce",
            "placeholder": "​",
            "style": "IPY_MODEL_5b3b0cc2318e4cbf9f2c7edd9404ea3f",
            "value": " 2/2 [01:17&lt;00:00, 36.10s/it]"
          }
        },
        "46a41677258149558d0df7f4de2bd124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38b42a7b0164b3b8f69a93dc65a85d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da7d206b0084bfbacacee65922d43bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0b05caa1d134ba4a7bcf66b86c97e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b76ba7f45804e93b02c4caf6ccf4b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b3a4bc17f35485bb426cdc5bf0049ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3b0cc2318e4cbf9f2c7edd9404ea3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d6065e39bcc4eb7974fda3df9aba82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08296439947e41c0b472820eb3928119",
              "IPY_MODEL_d3f448a6e0234280899cf8507023c940",
              "IPY_MODEL_3e6561f34b8c407a8197a2f59533a605"
            ],
            "layout": "IPY_MODEL_910beb7a492a4db4a7a46b9142d4c201"
          }
        },
        "08296439947e41c0b472820eb3928119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691fef6ed3064ec19b9e269a664cd930",
            "placeholder": "​",
            "style": "IPY_MODEL_7710eee904a24389b5513788a3f267ba",
            "value": "generation_config.json: 100%"
          }
        },
        "d3f448a6e0234280899cf8507023c940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf0d6783dbf49e7adca89bce3406c21",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8620efd05a184886bfb9e1f06af4916d",
            "value": 117
          }
        },
        "3e6561f34b8c407a8197a2f59533a605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79977e710ca54b1bb3c3246fc2ccfaf2",
            "placeholder": "​",
            "style": "IPY_MODEL_bbfbaccd333240faa3a5b89e61ef7660",
            "value": " 117/117 [00:00&lt;00:00, 6.56kB/s]"
          }
        },
        "910beb7a492a4db4a7a46b9142d4c201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691fef6ed3064ec19b9e269a664cd930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7710eee904a24389b5513788a3f267ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddf0d6783dbf49e7adca89bce3406c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8620efd05a184886bfb9e1f06af4916d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79977e710ca54b1bb3c3246fc2ccfaf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbfbaccd333240faa3a5b89e61ef7660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vigneshpatel14/NLP/blob/main/02_lanchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chains in LangChain** are sequences of actions that use different components such as language models, prompts, memory, or tools to achieve a task. Chains allow you to link multiple steps or processes together, such as querying a model, performing additional computation, and returning a final result."
      ],
      "metadata": {
        "id": "gzkRrzlTKnMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMaPX0KiK0br",
        "outputId": "af4edb29-dba8-4830-c7eb-8a9d3a094492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.9)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.11 (from langchain_community)\n",
            "  Downloading langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain_community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain_community) (2.27.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.9\n",
            "    Uninstalling langchain-0.3.9:\n",
            "      Successfully uninstalled langchain-0.3.9\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.11 langchain-core-0.3.24 langchain_community-0.3.11 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCm5Bt1lKl9G",
        "outputId": "e12b4a1a-d4df-4677-b234-041f0f3804b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a creative story about a magical forest.\n",
            "\n",
            "This is a beautiful piece of art. It's incredibly beautiful. It's not an abstract painting or something. It's a piece of art, and it's a piece of art is beautiful, but it's Dietary Coffee. It's a great picture of a place that you wasn't supposed to be there.\n",
            "\n",
            "It's incredibly beautiful. It's not an abstract painting or something. It's a piece of art, and it's a piece of art is beautiful, but it's Dietary Coffee. It's a great picture of a place that you wasn't supposed to be there.\n",
            "\n",
            "What is the flavor of this tea? Some people use it as a dessert for breakfast.\n",
            "\n",
            "Some people use it as a dessert for breakfast.\n",
            "\n",
            "You have a great recipe,anut butter flavored tea, with peanut butter. It's so perfect!\n",
            "\n",
            "You have a great recipe,anut butter flavored tea, with peanut butter. It's so perfect!\n",
            "\n",
            "What is the color of this tea?\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            "You get a beautiful flavor. It's a beautiful color.\n",
            "\n",
            " Place this in your coffee machine or on your counter.\n",
            "\n",
            "Place this in your coffee machine or on your counter.\n",
            "\n",
            "Do you know what the color is?\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. This is the fat partition of the cup.\n",
            "\n",
            "This is the fat partition of the cup. Church of the Lord Jesus Christ.\n",
            "\n",
            "This is the right color for a coffee machine.\n",
            "\n",
            "This is Ideas for a food processor.\n",
            "\n",
            "This is Ideas for a food processor.\n",
            "\n",
            "This is Ideas Furniture for a coffee machine.\n",
            "\n",
            "This is Ideas Furniture for a coffee machine.\n",
            "\n",
            "This is Ideas Furniture for a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n",
            "This is revolves in a coffee machine.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Set up Hugging Face model\n",
        "# You need an API key from Hugging Face to use HuggingFaceHub\n",
        "# Sign up at https://huggingface.co/settings/tokens and get an API key\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"gpt2\",  # Use \"gpt2\" as an example; replace with a suitable model\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 100},\n",
        "    huggingfacehub_api_token=\"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\"\n",
        ")\n",
        "\n",
        "# Define a prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Write a creative story about {topic}.\"\n",
        ")\n",
        "\n",
        "# Create a chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain with a specific input\n",
        "result = chain.run(topic=\"a magical forest\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Example: A Multi-Step Chain**"
      ],
      "metadata": {
        "id": "GuVHyn1iMwtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Initialize Hugging Face LLM with strict limits\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"gpt2\",  # Replace with another model if needed\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 50},  # Strict length control\n",
        "    huggingfacehub_api_token=\"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\"\n",
        ")\n",
        "\n",
        "# Step 1: Generate a concise description and FAQ in a single chain\n",
        "combined_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=(\n",
        "        \"Write a concise description of {topic}, followed by one FAQ-style question and its answer. \"\n",
        "        \"Keep everything brief.\"\n",
        "    )\n",
        ")\n",
        "combined_chain = LLMChain(llm=llm, prompt=combined_prompt)\n",
        "\n",
        "# Function to run the chain\n",
        "def generate_combined_faq(topic):\n",
        "    return combined_chain.run(topic=topic)\n",
        "\n",
        "# Input topic\n",
        "topic = \"Artificial Intelligence\"\n",
        "\n",
        "# Run the chain\n",
        "result = generate_combined_faq(topic)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBKqzQwKMvxZ",
        "outputId": "d9f502de-bcbd-4bf3-bb98-36c79e13235b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a concise description of Artificial Intelligence, followed by one FAQ-style question and its answer. Keep everything brief.\n",
            "\n",
            "You can also ask questions in the FAQs section of the web site.\n",
            "\n",
            "The question was put up for discussion during the AMA. The title of this post is \"How can I help? Should I ask questions in the FAQs section?\".\n",
            "\n",
            "This post has 17 comments and it was chosen from over 100. The answers to these questions can be found here.\n",
            "\n",
            "The question was published on a conversation on the AskReddit.com forum. You can read the full post here.\n",
            "\n",
            "After the AMA, the maximum number of responses can be reached. The maximum number of replies is 15.\n",
            "\n",
            "The answers to the questions on AskReddit.com are given below.\n",
            "\n",
            "Q: How do I respond to questions in the FAQs section?\n",
            "\n",
            "A: Start by asking questions in the FAQs section. There are a lot of questions that can be answered in the FAQs section.\n",
            "\n",
            "As you can see, there are over 10,000 questions in the FAQs section. One of the main reasons is simple. There are beginner questions asking why the computer is not responding to your question, but they will not be answered in the FAQs section.\n",
            "\n",
            "Q: Where do I put my questions in the FAQs section?\n",
            "\n",
            "A: In the FAQs section. On the left you can see a list of answers to your question.\n",
            "\n",
            "Q: Why should I use the old form of the question?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: Why do I need to use the old form of the question?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: Why do I need to use the old form of the question?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: Why do I need to use the old form of the question?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: Why do I need to use the old form of the question?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question in a more concise way?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: When do I Goodell take the knee?\n",
            "\n",
            "A: The end of their game.\n",
            "\n",
            "Q: Why do I see the NFL players kneeling?\n",
            "\n",
            "A: The end of their game.\n",
            "\n",
            "Q: Why do I see the NFL players kneeling?\n",
            "\n",
            "A: The end of their game.\n",
            "\n",
            "Q: What does the NFL say about this?\n",
            "\n",
            "A: Themberg Laws of Germany. This is a controversial issue around the world.\n",
            "\n",
            "Q: What does the NFL say about this?\n",
            "\n",
            "A: Themberg Laws of Germany. This is a controversial issue around the world.\n",
            "\n",
            "Q: Should I put the question engulfing me in a question about the NFL?\n",
            "\n",
            "A: Should I put the question engulfing me in a question about the NFL?\n",
            "\n",
            "Q: How do I put the question engulfing me in a question about the NFL?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: Why do I need to put the question engulfing me in a question about the NFL?\n",
            "\n",
            "A: For the purpose of a more general question. The answer will look like this.\n",
            "\n",
            "Q: How do I put the question engulfing me in a question about the NFL?\n",
            "\n",
            "A: For the purpose of a more general question. The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Sequential Chain**"
      ],
      "metadata": {
        "id": "9mxx2uXnYrWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "# Initialize Hugging Face LLM with a different model\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"facebook/opt-350m\",  # A model with a higher token limit\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 100},  # Slightly more tokens allowed\n",
        "    huggingfacehub_api_token=\"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\"\n",
        ")\n",
        "\n",
        "# Step 1: Generate a job description based on the job title\n",
        "job_description_prompt = PromptTemplate(\n",
        "    input_variables=[\"job_title\"],\n",
        "    template=\"Write a brief job description for the position of {job_title}. Keep it concise.\"\n",
        ")\n",
        "job_description_chain = LLMChain(llm=llm, prompt=job_description_prompt)\n",
        "\n",
        "# Step 2: Generate interview questions based on the job description\n",
        "interview_questions_prompt = PromptTemplate(\n",
        "    input_variables=[\"job_description\"],\n",
        "    template=\"Based on the job description, create two relevant interview questions:\\n\\n{job_description}\"\n",
        ")\n",
        "interview_questions_chain = LLMChain(llm=llm, prompt=interview_questions_prompt)\n",
        "\n",
        "# Combine the chains into a Simple Sequential Chain\n",
        "job_application_chain = SimpleSequentialChain(chains=[job_description_chain, interview_questions_chain])\n",
        "\n",
        "# Run the chain with a job title\n",
        "job_title = \"Machine Learning Engineer\"\n",
        "result = job_application_chain.run(job_title)\n",
        "\n",
        "print(\"Final Output:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgOAsQBeRegM",
        "outputId": "dec33fa2-0482-486e-c074-4e76bc9fd190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Output:\n",
            "Based on the job description, create two relevant interview questions:\n",
            "\n",
            "Write a brief job description for the position of Machine Learning Engineer. Keep it concise.\n",
            "\n",
            "9.5 out of 10\n",
            "\n",
            "Business Analyst\n",
            "\n",
            "Sections: Data Science, Machine Learning, Finance, Information Security, Security & Privacy\n",
            "\n",
            "Job Overview\n",
            "\n",
            "I am currently looking for a Business Analyst to join our Data Science team. The role will provide fundamental insights into the process and objectives of the data scientists and data engineers working on our product. This will involve analyzing data through the analysis of a broad range of approaches, including:\n",
            "\n",
            "Analytics\n",
            "\n",
            "Data Analysis\n",
            "\n",
            "Data Flow\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Mining\n",
            "\n",
            "Data Management\n",
            "\n",
            "Data Visualisation\n",
            "\n",
            "Data Science\n",
            "\n",
            "Data Analysis\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Visualisation\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Machine learning\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Management Louisiana State University Business Analyst is a highly technical, data scientist with a passion for machine learning and deep data analytics, according to our job description. This position will help us to identify and understand big data and machine learning challenges in our industry. As a Data Scientist, you will be responsible for the analysis and discovery of Big Data. You will collaborate with data scientists, data engineers and data scientists\n",
            "\n",
            "You will have the opportunity to work on a wide range of machine learning projects, including but not limited to:\n",
            "\n",
            "Data Analysis\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Visualisation\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Machine Learning\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Machine Learning\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data Engineering\n",
            "\n",
            "Data EngineeringICA has been a leader in the fields of Machine Learning, Data Science, and AI, serving clients in a number of industries. We are part of the Data Science Space, a network of scientific organizations that connects with other research and technical organizations that are focused on meeting the data science needs of our clients.251.225.0258\n",
            "\n",
            "The position will be a part time position and will be paid from August through December 2020. This full time position will start at $18.00 per hour.\n",
            "\n",
            "This position is being provided by IAC in collaboration with the University of Southern California. Information about the position will be available in the Data Science Space.\n",
            "\n",
            "This position will be a part time position and will be paid from August through December 2020. This full time position will start at $18.00 per hour.\n",
            "\n",
            "This position is being provided by IAC in collaboration with the University of Southern California. Information about the position will be available in the Data Science Space.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agents and Tools**"
      ],
      "metadata": {
        "id": "573wNYOVYuUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain transformers accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY6urWnWbIMS",
        "outputId": "da5e4d7e-7e57-41cc-b6c2-4099e59d2cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "# Create a text-generation pipeline\n",
        "falcon_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "428b7029386d4f44a88674ffa2c79881",
            "1412f8066a224971b738b743952bc195",
            "6256359a6f2442ccb025b27ba501fffa",
            "7c23e6c95df6474a81594615a7d9b2ef",
            "46a41677258149558d0df7f4de2bd124",
            "e38b42a7b0164b3b8f69a93dc65a85d4",
            "7da7d206b0084bfbacacee65922d43bc",
            "a0b05caa1d134ba4a7bcf66b86c97e9b",
            "0b76ba7f45804e93b02c4caf6ccf4b89",
            "7b3a4bc17f35485bb426cdc5bf0049ce",
            "5b3b0cc2318e4cbf9f2c7edd9404ea3f",
            "5d6065e39bcc4eb7974fda3df9aba82d",
            "08296439947e41c0b472820eb3928119",
            "d3f448a6e0234280899cf8507023c940",
            "3e6561f34b8c407a8197a2f59533a605",
            "910beb7a492a4db4a7a46b9142d4c201",
            "691fef6ed3064ec19b9e269a664cd930",
            "7710eee904a24389b5513788a3f267ba",
            "ddf0d6783dbf49e7adca89bce3406c21",
            "8620efd05a184886bfb9e1f06af4916d",
            "79977e710ca54b1bb3c3246fc2ccfaf2",
            "bbfbaccd333240faa3a5b89e61ef7660"
          ]
        },
        "id": "-M6ExpxSbSmT",
        "outputId": "cc4c5928-82bd-4ae8-d2ab-c27a06ebe056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "428b7029386d4f44a88674ffa2c79881"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d6065e39bcc4eb7974fda3df9aba82d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "def falcon_tool(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    A tool that uses Falcon-7B-Instruct for text generation.\n",
        "    \"\"\"\n",
        "    response = falcon_pipeline(prompt)\n",
        "    return response[0][\"generated_text\"]\n",
        "\n",
        "# Define the tool explicitly\n",
        "falcon_tool = Tool(\n",
        "    name=\"FalconTool\",\n",
        "    func=falcon_tool,\n",
        "    description=\"A tool for generating text using Falcon-7B-Instruct.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "t8lehYNIi7mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Define tools (add FalconTool)\n",
        "tools = [\n",
        "    Tool(name=\"FalconTool\", func=falcon_tool, description=\"Generate text using Falcon-7B-Instruct.\")\n",
        "]\n",
        "\n",
        "# Use a chat model for agent reasoning\n",
        "chat_model = ChatOpenAI(temperature=0.7, openai_api_key=\"your-api-key\")  # Replace with valid key\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(tools, chat_model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Test the agent\n",
        "response = agent.run(\"Write a story about a robot exploring Mars.\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "L_xKmp-xjGH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}